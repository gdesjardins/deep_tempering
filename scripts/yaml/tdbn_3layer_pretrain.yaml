!obj:pylearn2.scripts.train.Train {
    "dataset": &data !obj:deep_tempering.data.test_modes.OnlineModesNIPSDLUFL {},
    "model": &model !obj:deep_tempering.tempered_dbn.TemperedDBN {
        "max_updates": &maxupdates 1000000,
        "flags": {
            'train_on_samples': 0,
            'pretrain': 1,
        },
        "rbm1": &rbm1 !obj:deep_tempering.rbm.RBM {
                "seed" : 34789,
                "batch_size" : &batch_size 100,
                "n_v"  : 784,
                "n_h"  : &nh1 10,
                "gibbs_vhv": True,
                "neg_sample_steps" : 1,
                "flags": {
                    'ml_vbias': 0,
                    'enable_centering': 1,
                },
                "lr_spec"  : {
                    'type': 'linear',
                    'start': 0.001,
                    'end': 0.001,
                },
                # WARNING: change default values before
                "lr_mults": {},
                "iscales" : {
                    'Wv': 0.01,
                    'hbias':0.,
                    'vbias':0.,
                },
                "sp_weight": {"h":0.},
                "sp_targ"  : {"h":0.2},
                "debug": True,
                "max_updates": *maxupdates,
        },
        "rbm2": &rbm2 !obj:deep_tempering.rbm.RBM {
                "seed" : 34790,
                "batch_size" : *batch_size,
                "n_v"  : *nh1,
                "n_h"  : &nh2 10,
                "gibbs_vhv": True,
                "neg_sample_steps" : 1,
                "flags": {
                    'ml_vbias': 0,
                    'enable_centering': 1,
                },
                "lr_spec"  : {
                    'type': 'linear',
                    'start': 0.001,
                    'end': 0.001,
                },
                # WARNING: change default values before
                "lr_mults": {},
                "iscales" : {
                    'Wv': 0.01,
                    'hbias':0.,
                    'vbias':0.,
                },
                "sp_weight": {"h":0.},
                "sp_targ"  : {"h":0.2},
                "debug": True,
                "max_updates": *maxupdates,
        },
        "rbm3": &rbm3 !obj:deep_tempering.rbm.RBM {
                "seed" : 34790,
                "batch_size" : *batch_size,
                "n_v"  : *nh2,
                "n_h"  : &nh3 10,
                "gibbs_vhv": True,
                "neg_sample_steps" : 1,
                "flags": {
                    'ml_vbias': 0,
                    'enable_centering': 1,
                },
                "lr_spec"  : {
                    'type': 'linear',
                    'start': 0.001,
                    'end': 0.001,
                },
                # WARNING: change default values before
                "lr_mults": {},
                "iscales" : {
                    'Wv': 0.01,
                    'hbias':0.,
                    'vbias':0.,
                },
                "sp_weight": {"h":0.},
                "sp_targ"  : {"h":0.2},
                "debug": True,
                "max_updates": *maxupdates,
        },
        "rbms": [*rbm1, *rbm2, *rbm3],
    },
    "algorithm": !obj:deep_tempering.training_algorithm.TrainingAlgorithm {
               "batch_size": *batch_size,
               "batches_per_iter" : 1000,
               "monitoring_batches": 11,
               # not used but required by pylearn2
               "monitoring_dataset": !obj:pylearn2.datasets.mnist.MNIST {
                    "which_set": 'train',
                    "one_hot": 1.,
                },
    },
    "callbacks": [
        !obj:deep_tempering.scripts.likelihood.rbm_pretrain_callback.pylearn2_rbm_pretrain_callback {
            "interval": 1000,
            "trainset": *data,
            "layer": 0,
        },
        !obj:deep_tempering.scripts.likelihood.rbm_pretrain_callback.pylearn2_rbm_pretrain_callback {
            "interval": 1000,
            "trainset": *data,
            "layer": 1,
        },
        !obj:deep_tempering.scripts.likelihood.dbn_callback.pylearn2_dbn_likelihood_callback {
            "interval": 1000,
            "trainset": *data,
            "layer": 2,
        },
        !obj:deep_tempering.scripts.likelihood.log_swap_callback.pylearn2_log_swap_callback {
            "interval": 1000,
        },
        !obj:deep_tempering.save_callback.pylearn2_save_callback {
            "save_every": 1000,
            "save_at": [],
            "my_save_path": "model",
        },
    ]
}

